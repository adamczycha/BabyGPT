{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tiktoken\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_examples():\n",
    "    with open('benchmarks/hellaswag/hellaswag_val.jsonl', 'rb') as file:\n",
    "        for line in file:\n",
    "            example = json.loads(line)\n",
    "            yield example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iterate_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_example(example):\n",
    "    ctx = example['ctx']\n",
    "    endings = example['endings']\n",
    "    label = example['label']\n",
    "    \n",
    "    enc = tiktoken.get_encoding('gpt2')\n",
    "    ctx_tokens = enc.encode(ctx)\n",
    "    tok_rows = []\n",
    "    mask_rows = []\n",
    "    for end in endings:\n",
    "        end_tokens = enc.encode(' '+ end)\n",
    "        tok_rows.append(ctx_tokens + end_tokens)\n",
    "        mask_rows.append([0] * len(ctx_tokens) + [1] * len(end_tokens))\n",
    "\n",
    "    tokens = torch.zeros([4,1024], dtype=torch.long)\n",
    "    mask = torch.zeros([4,1024], dtype=torch.long)\n",
    "    for i,(tok_row, mask_row) in enumerate(zip(tok_rows, mask_rows)):\n",
    "        tokens[i,:len(tok_row)] = torch.tensor([tok_row]) \n",
    "        mask[i,:len(mask_row)] = torch.tensor([mask_row])\n",
    "    \n",
    "    \n",
    "    return tokens, mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.zeros([4,1024], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[0, :10] = torch.tensor([1] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7571, 1466,  287,  ...,    0,    0,    0],\n",
       "         [7571, 1466,  287,  ...,    0,    0,    0],\n",
       "         [7571, 1466,  287,  ...,    0,    0,    0],\n",
       "         [7571, 1466,  287,  ...,    0,    0,    0]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 2)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_example(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten[0,-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7571, 1466,  287,  ...,    0,    0,    0],\n",
       "         [7571, 1466,  287,  ...,    0,    0,    0],\n",
       "         [7571, 1466,  287,  ...,    0,    0,    0],\n",
       "         [7571, 1466,  287,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 2)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "    model.to(device)\n",
    "    hella_val = iterate_examples()\n",
    "    for example in hella_val:\n",
    "        tokens, mask, lable = prepare_example(example)\n",
    "        tokens, mask = tokens.to(device), mask.to(device)\n",
    "        model(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sentenses = list(map(lambda x: ctx + ' ' +  x, endings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7571, 1466,  287,  ...,    0,    0,    0],\n",
       "        [7571, 1466,  287,  ...,    0,    0,    0],\n",
       "        [7571, 1466,  287,  ...,    0,    0,    0],\n",
       "        [7571, 1466,  287,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[246, 246, 216, 278]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
